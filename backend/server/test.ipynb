{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Fine Tune SAM 2 on LabPics 1 dataset\n",
    "# This mode use several images in a single batch\n",
    "# Labpics can be downloaded from: https://zenodo.org/records/3697452/files/LabPicsV1.zip?download=1\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.ndimage import label\n",
    "import cv2\n",
    "import os\n",
    "import tifffile\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "from torch.onnx.symbolic_opset11 import hstack\n",
    "\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "\n",
    "outdir = r\"/Volumes/Chris_SSD/AllSegmentations/SAM2_processed/Mito/\" \n",
    "data_dir=r\"/Volumes/Chris_SSD/AllSegmentations/Lab/Mito/Liver/\" \n",
    "\n",
    "def preprocess_data_for_sam(indir, outdir):\n",
    "    data=[] # list of files in dataset\n",
    "    for ff, name in enumerate(os.listdir(os.path.join(indir, \"EM\"))):\n",
    "        img_inpath = os.path.join(data_dir, \"EM\", name)\n",
    "        if not os.path.exists(img_inpath) or not os.path.exists(os.path.join(data_dir, \"Masks\", name)):\n",
    "            continue\n",
    "        annotation = tifffile.imread(os.path.join(data_dir,\"Masks\",name)).astype(np.uint8)\n",
    "        labeled_array, num_features = label(annotation)\n",
    "        for i in range(1, num_features + 1):\n",
    "            separate_mask = (labeled_array == i).astype(np.uint8) * 255  # Convert to 0 and 255\n",
    "            separate_mask = separate_mask[:1024, :1024] # Crop to 1024x1024\n",
    "            if np.max(separate_mask) < 1:\n",
    "                continue  \n",
    "            output_image = Image.fromarray(separate_mask)\n",
    "            output_image.save(os.path.join(outdir, \"annotation\", f\"{name[:-4]}_{i}.tif\"))\n",
    "            img_path = os.path.join(outdir, \"image\", name)\n",
    "            if not Path(img_path).exists():\n",
    "                img = np.array(cv2.imread(img_inpath), dtype=np.uint8)[:1024, :1024, :]\n",
    "                cv2.imwrite(img_path, img)\n",
    "preprocess_data_for_sam(data_dir, outdir)\n",
    "\n",
    "def read_single(traindir): # read random image and single mask from  the dataset (LabPics)\n",
    "    annotation_fns = [os.path.join(traindir, \"annotation\", x) for x in os.listdir(os.path.join(traindir, \"annotation\"))]\n",
    "\n",
    "    # select image and annotation\n",
    "    index  = np.random.randint(len(annotation_fns)) # choose random entry\n",
    "    mask = cv2.imread(annotation_fns[index]) # read annotation\n",
    "    img_name = \"_\".join(os.path.basename(annotation_fns[index]).split(\"_\")[0:-1]) + \".tif\"\n",
    "    Img = cv2.imread(os.path.join(traindir, \"image\", img_name))[...,::-1]  # read image\n",
    "    coords = np.argwhere(mask > 0) # get all coordinates in mask\n",
    "    cv2rect = cv2.boundingRect(coords) # get bounding box of mask\n",
    "    bbox = [\n",
    "        cv2rect[0]- np.random.randint(0, 20), \n",
    "        cv2rect[1]- np.random.randint(0, 20), \n",
    "        cv2rect[0] + cv2rect[2]+ np.random.randint(0, 20), \n",
    "        cv2rect[1] + cv2rect[3]+ np.random.randint(0, 20)\n",
    "    ] # convert to bbox format with random padding\n",
    "    yx = np.array(coords[np.random.randint(len(coords))]) # choose random point/coordinate\n",
    "    return Img,mask,[[yx[1], yx[0]]],bbox\n",
    "\n",
    "def read_batch(traindir,batch_size=4):\n",
    "    limage = []\n",
    "    lmask = []\n",
    "    linput_point = []\n",
    "    lbbox = []\n",
    "    for i in range(batch_size):\n",
    "        image,mask,input_point,bbox = read_single(traindir)\n",
    "        limage.append(image)\n",
    "        lmask.append(mask)\n",
    "        linput_point.append(input_point)\n",
    "        lbbox.append(bbox)\n",
    "\n",
    "    return limage, np.array(lmask), np.array(linput_point),  np.ones([batch_size,1]), np.array(lbbox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "sam2_checkpoint = \"sam2_hiera_small.pt\" # path to model weight\n",
    "model_cfg = \"sam2_hiera_s.yaml\" #  model config\n",
    "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\") # load model\n",
    "predictor = SAM2ImagePredictor(sam2_model)\n",
    "\n",
    "# Set training parameters\n",
    "\n",
    "predictor.model.sam_mask_decoder.train(True) # enable training of mask decoder\n",
    "predictor.model.sam_prompt_encoder.train(True) # enable training of prompt encoder\n",
    "predictor.model.image_encoder.train(True) # enable training of image encoder: For this to work you need to scan the code for \"no_grad\" and remove them all\n",
    "optimizer=torch.optim.AdamW(params=predictor.model.parameters(),lr=1e-5,weight_decay=4e-5)\n",
    "scaler = torch.cuda.amp.GradScaler() # mixed precision\n",
    "\n",
    "# Training loop\n",
    "\n",
    "for itr in range(100000):\n",
    "    with torch.cuda.amp.autocast(): # cast to mix precision\n",
    "            image,mask,input_point, input_label = read_batch(outdir,batch_size=4) # load data batch\n",
    "            if mask.shape[0]==0: continue # ignore empty batches\n",
    "            predictor.set_image_batch(image) # apply SAM image encoder to the image\n",
    "            # predictor.get_image_embedding()\n",
    "            # prompt encoding\n",
    "\n",
    "            mask_input, unnorm_coords, labels, unnorm_box = predictor._prep_prompts(input_point, input_label, box=None, mask_logits=None, normalize_coords=True)\n",
    "            sparse_embeddings, dense_embeddings = predictor.model.sam_prompt_encoder(points=(unnorm_coords, labels),boxes=None,masks=None,)\n",
    "\n",
    "            # mask decoder\n",
    "\n",
    "            high_res_features = [feat_level[-1].unsqueeze(0) for feat_level in predictor._features[\"high_res_feats\"]]\n",
    "            low_res_masks, prd_scores, _, _ = predictor.model.sam_mask_decoder(image_embeddings=predictor._features[\"image_embed\"],image_pe=predictor.model.sam_prompt_encoder.get_dense_pe(),sparse_prompt_embeddings=sparse_embeddings,dense_prompt_embeddings=dense_embeddings,multimask_output=True,repeat_image=False,high_res_features=high_res_features,)\n",
    "            prd_masks = predictor._transforms.postprocess_masks(low_res_masks, predictor._orig_hw[-1])# Upscale the masks to the original image resolution\n",
    "\n",
    "            # Segmentaion Loss caclulation\n",
    "\n",
    "            gt_mask = torch.tensor(mask.astype(np.float32)).cuda()\n",
    "            prd_mask = torch.sigmoid(prd_masks[:, 0])# Turn logit map to probability map\n",
    "            seg_loss = (-gt_mask * torch.log(prd_mask + 0.00001) - (1 - gt_mask) * torch.log((1 - prd_mask) + 0.00001)).mean() # cross entropy loss\n",
    "\n",
    "            # Score loss calculation (intersection over union) IOU\n",
    "\n",
    "            inter = (gt_mask * (prd_mask > 0.5)).sum(1).sum(1)\n",
    "            iou = inter / (gt_mask.sum(1).sum(1) + (prd_mask > 0.5).sum(1).sum(1) - inter)\n",
    "            score_loss = torch.abs(prd_scores[:, 0] - iou).mean()\n",
    "            loss=seg_loss+score_loss*0.05  # mix losses\n",
    "\n",
    "            # apply back propogation\n",
    "\n",
    "            predictor.model.zero_grad() # empty gradient\n",
    "            scaler.scale(loss).backward()  # Backpropogate\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update() # Mix precision\n",
    "\n",
    "            if itr%1000==0: torch.save(predictor.model.state_dict(), \"model.torch\") # save model\n",
    "\n",
    "            # Display results\n",
    "\n",
    "            if itr==0: mean_iou=0\n",
    "            mean_iou = mean_iou * 0.99 + 0.01 * np.mean(iou.cpu().detach().numpy())\n",
    "            print(\"step)\",itr, \"Accuracy(IOU)=\",mean_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
