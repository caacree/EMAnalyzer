{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  All matching files have been chunked and saved.\n"
     ]
    }
   ],
   "source": [
    "# ⬇️ Put everything in one notebook cell ⬇️\n",
    "from pathlib import Path\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "\n",
    "def chunk_bsd_tf_images(\n",
    "    input_root: str | Path,\n",
    "    output_root: str | Path,\n",
    "    chunk_size: int = 10_000,\n",
    "    compression: str | None = \"zlib\",   # lossless; set to None for no compression\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Recursively walk `input_root`, find images whose filenames end with `_bsd.tf`,\n",
    "    split each into square `chunk_size` patches, and save them under `output_root`.\n",
    "\n",
    "    Filenames are written as:\n",
    "        {orig_stem}_{y0}_{x0}{orig_suffix}\n",
    "\n",
    "    where (x0, y0) are the *upper-left* pixel indices of the patch in the\n",
    "    original image.  The original sub-directory structure is mirrored beneath\n",
    "    `output_root`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_root : str or Path\n",
    "        Directory tree to search.\n",
    "    output_root : str or Path\n",
    "        Destination directory tree.\n",
    "    chunk_size : int, default 10_000\n",
    "        Pixel width/height of each square patch.\n",
    "    compression : str | None, default \"zlib\"\n",
    "        tifffile lossless compression to use when writing.  `None` disables it.\n",
    "    \"\"\"\n",
    "    input_root  = Path(input_root).expanduser().resolve()\n",
    "    output_root = Path(output_root).expanduser().resolve()\n",
    "    output_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for tiff_path in input_root.rglob(\"*.tif\"):\n",
    "        last_part = tiff_path.name.split(\"/\")[-1]\n",
    "        if last_part.startswith(\".\"):\n",
    "            continue\n",
    "        print(f\"Processing {tiff_path.name.split(\"/\")[-1]}\")\n",
    "        # Map TIFF lazily so huge files do not fill memory\n",
    "        img = tiff.imread(tiff_path)\n",
    "        height, width = img.shape[:2]\n",
    "\n",
    "        # Where to recreate the sub-folder tree\n",
    "        rel_parent = tiff_path.relative_to(input_root).parent\n",
    "        out_parent = output_root / rel_parent\n",
    "        out_parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Iterate over chunk origins\n",
    "        for y0 in range(0, height, chunk_size):\n",
    "            for x0 in range(0, width, chunk_size):\n",
    "                y1, x1 = y0 + chunk_size, x0 + chunk_size\n",
    "                patch = img[y0:y1, x0:x1]\n",
    "\n",
    "                out_name = f\"{tiff_path.stem}_{y0}_{x0}{tiff_path.suffix}\"\n",
    "                out_path = out_parent / out_name\n",
    "\n",
    "                # Preserve dtype; write with optional lossless compression\n",
    "                tiff.imwrite(out_path, patch, compression=compression)\n",
    "\n",
    "        # Explicitly close memmap to release file handle\n",
    "        del img\n",
    "\n",
    "    print(\"✅  All matching files have been chunked and saved.\")\n",
    "\n",
    "# Example call:\n",
    "input_folder = \"/Volumes/Chris_SSD/file_shuttle/20250630-DZX-pt1/EM\"\n",
    "output_folder = \"/Volumes/Chris_SSD/file_shuttle/20250630-DZX-pt1/EM-chunked\"\n",
    "chunk_bsd_tf_images(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written mosaic: 25-0073_5nm_Region12_bsd.tif (64640×32629)\n",
      "Written mosaic: 25-0075_5nm_Region11_bsd.tif (33565×35375)\n",
      "Written mosaic: 25-0077_5nm_R11_bsd.tif (21810×54124)\n",
      "Written mosaic: 25-0079_5nm_R10_bsd.tif (24079×67298)\n",
      "Written mosaic: 25-0081_5nm_R13_bsd.tif (32515×26702)\n",
      "Written mosaic: 25-0081_5nm_R7_bsd.tif (23199×34038)\n",
      "Written mosaic: 25-0083_5nm_R14_bsd.tif (49972×42486)\n",
      "Written mosaic: 25-0085_5nm_Region13_bsd.tif (47416×31866)\n",
      "Written mosaic: 25-0087_5nm_Region17_bsd.tif (38633×72488)\n",
      "Written mosaic: 25-0089_5nm_Region15_bsd.tif (39248×53185)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tifffile\n",
    "\n",
    "def img_unchunker(input_folder: str, output_folder: str) -> None:\n",
    "    \"\"\"\n",
    "    Scan `input_folder` for tiles named like\n",
    "      processed_<base>_x{X}_y{Y}.tif\n",
    "    Group by <base>, stitch all tiles into one big mosaic according to their (X,Y) offsets,\n",
    "    and save each mosaic in `output_folder` as <base>.tif (dropping the \"processed_\" prefix).\n",
    "\n",
    "    Args:\n",
    "        input_folder: path to folder containing the processed_*.tif tiles\n",
    "        output_folder: path to folder where full mosaics will be written\n",
    "    \"\"\"\n",
    "    input_path = Path(input_folder)\n",
    "    output_path = Path(output_folder)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # regex to extract base, x, and y\n",
    "    pattern = re.compile(r'^processed_(?P<base>.+?)_x(?P<x>\\d+)_y(?P<y>\\d+)\\.tif$')\n",
    "\n",
    "    # collect tiles\n",
    "    groups = {}\n",
    "    for tif in input_path.glob('processed_*.tif'):\n",
    "        m = pattern.match(tif.name)\n",
    "        if not m:\n",
    "            continue\n",
    "        base = m.group('base')\n",
    "        x = int(m.group('x'))\n",
    "        y = int(m.group('y'))\n",
    "        groups.setdefault(base, []).append((tif, x, y))\n",
    "\n",
    "    # process each group\n",
    "    for base, tiles in groups.items():\n",
    "        # first pass: determine output mosaic size\n",
    "        max_x = max_x_extent = 0\n",
    "        max_y = max_y_extent = 0\n",
    "        dtype = None\n",
    "\n",
    "        for fp, x, y in tiles:\n",
    "            arr = tifffile.imread(str(fp))\n",
    "            h, w = arr.shape[:2]\n",
    "            dtype = arr.dtype\n",
    "            max_x_extent = max(max_x_extent, x + w)\n",
    "            max_y_extent = max(max_y_extent, y + h)\n",
    "\n",
    "        # allocate mosaic\n",
    "        mosaic = np.zeros((max_y_extent, max_x_extent), dtype=dtype)\n",
    "\n",
    "        # second pass: copy each tile into the mosaic\n",
    "        for fp, x, y in tiles:\n",
    "            arr = tifffile.imread(str(fp))\n",
    "            h, w = arr.shape[:2]\n",
    "            mosaic[y:y+h, x:x+w] = arr\n",
    "\n",
    "        # write out\n",
    "        out_name = f\"{base}.tif\"\n",
    "        tifffile.imwrite(str(output_path / out_name), mosaic)\n",
    "        print(f\"Written mosaic: {out_name} ({max_x_extent}×{max_y_extent})\")\n",
    "\n",
    "input_folder = \"/Volumes/Chris_SSD/lds_20250625\"\n",
    "output_folder = \"/Volumes/Chris_SSD/lds_20250625_8bit\"\n",
    "\n",
    "#img_unchunker(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
